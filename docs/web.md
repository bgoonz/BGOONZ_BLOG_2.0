2021-07-26

Web Scraping with Node.js
=========================

> So whatâ€™s web scraping anyway? It involves automating away the laborious task of collecting information from websites. There are a lot of use cases for web scraping: you might want to collect prices from various e-commerce sites for a price comparison site. Or perhaps you need flight times and

![The Ultimate Guide to Web Scraping with Node.js](https://cdn-media-1.freecodecamp.org/images/1*KkVKtysvgh2hIVRI1Irk-Q.jpeg)

So whatâ€™s web scraping anyway? It involves automating away the laborious task of collecting information from websites.

There are a lot of use cases for web scraping: you might want to collect prices from various e-commerce sites for a price comparison site. Or perhaps you need flight times and hotel/AirBNB listings for a travel site. Maybe you want to collect emails from various directories for sales leads, or use data from the internet to train machine learning/AI models. Or you could even be wanting to build a search engine like Google!

Getting started with web scraping is easy, and the process can be broken down into two main parts:

-   acquiring the data using an HTML request library or a headless browser,
-   and parsing the data to get the exact information you want.

This guide will walk you through the process with the popular Node.js [request-promise](https://github.com/request/request-promise) module, [CheerioJS](https://github.com/cheeriojs/cheerio), and [Puppeteer](https://github.com/GoogleChrome/puppeteer). Working through the examples in this guide, you will learn all the tips and tricks you need to become a pro at gathering any data you need with Node.js!

We will be gathering a list of all the names and birthdays of U.S. presidents from Wikipedia and the titles of all the posts on the front page of Reddit.

First things first: Letâ€™s install the libraries weâ€™ll be using in this guide (Puppeteer will take a while to install as it needs to download Chromium as well).

### Making your first request

<table><tbody><tr class="odd"><td></td><td>npm install â€“save request request-promise cheerio puppeteer</td></tr></tbody></table>

Next, letâ€™s open a new text file (name the file potusScraper.js), and write a quick function to get the HTML of the Wikipedia â€œList of Presidentsâ€ page.

<table><tbody><tr class="odd"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="even"><td></td><td>const url = â€˜https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_Statesâ€™;</td></tr><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>rp(url)</td></tr><tr class="odd"><td></td><td>.then(function(html){</td></tr><tr class="even"><td></td><td>//success!</td></tr><tr class="odd"><td></td><td>console.log(html);</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.catch(function(err){</td></tr><tr class="even"><td></td><td>//handle error</td></tr><tr class="odd"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td>&lt;!DOCTYPE html&gt;</td></tr><tr class="even"><td></td><td>&lt;html class=â€œclient-nojsâ€ lang=â€œenâ€ dir=â€œltrâ€&gt;</td></tr><tr class="odd"><td></td><td>&lt;head&gt;</td></tr><tr class="even"><td></td><td>&lt;meta charset=â€œUTF-8â€/&gt;</td></tr><tr class="odd"><td></td><td>&lt;title&gt;List of Presidents of the United States - Wikipedia&lt;/title&gt;</td></tr><tr class="even"><td></td><td>â€¦</td></tr></tbody></table>

### Using Chrome DevTools

Cool, we got the raw HTML from the web page! But now we need to make sense of this giant blob of text. To do that, weâ€™ll need to use Chrome DevTools to allow us to easily search through the HTML of a web page.

Using Chrome DevTools is easy: simply open Google Chrome, and right click on the element you would like to scrape (in this case I am right clicking on George Washington, because we want to get links to all of the individual presidentsâ€™ Wikipedia pages):

![](https://cdn-media-1.freecodecamp.org/images/1*gLKhu_EO-cDqYna1P9WL_w.png)

Now, simply click inspect, and Chrome will bring up its DevTools pane, allowing you to easily inspect the pageâ€™s source HTML.

![](https://cdn-media-1.freecodecamp.org/images/1*HSUjFgji22vjwvGi2uZe1A.png)

### Parsing HTML with Cheerio.js

Awesome, Chrome DevTools is now showing us the exact pattern we should be looking for in the code (a â€œbigâ€ tag with a hyperlink inside of it). Letâ€™s use Cheerio.js to parse the HTML we received earlier to return a list of links to the individual Wikipedia pages of U.S. presidents.

<table><tbody><tr class="odd"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="even"><td></td><td>const $ = require(â€˜cheerioâ€™);</td></tr><tr class="odd"><td></td><td>const url = â€˜https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_Statesâ€™;</td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td>rp(url)</td></tr><tr class="even"><td></td><td>.then(function(html){</td></tr><tr class="odd"><td></td><td>//success!</td></tr><tr class="even"><td></td><td>console.log(<span class="math inline">$('big &amp;gt; a', html).length);&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td id="file-potusscraper-js-v2-L9" data-line-number="9"&gt;&lt;/td&gt;&lt;td id="file-potusscraper-js-v2-LC9"&gt;console.log($</span>(â€˜big &gt; aâ€™, html));</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>.catch(function(err){</td></tr><tr class="odd"><td></td><td>//handle error</td></tr><tr class="even"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td>45</td></tr><tr class="even"><td></td><td>{ â€˜0â€™:</td></tr><tr class="odd"><td></td><td>{ type: â€˜tagâ€™,</td></tr><tr class="even"><td></td><td>name: â€˜aâ€™,</td></tr><tr class="odd"><td></td><td>attribs: { href: â€˜/wiki/George_Washingtonâ€™, title: â€˜George Washingtonâ€™ },</td></tr><tr class="even"><td></td><td>children: [ [Object] ],</td></tr><tr class="odd"><td></td><td>next: null,</td></tr><tr class="even"><td></td><td>prev: null,</td></tr><tr class="odd"><td></td><td>parent:</td></tr><tr class="even"><td></td><td>{ type: â€˜tagâ€™,</td></tr><tr class="odd"><td></td><td>name: â€˜bigâ€™,</td></tr><tr class="even"><td></td><td>attribs: {},</td></tr><tr class="odd"><td></td><td>children: [Array],</td></tr><tr class="even"><td></td><td>next: null,</td></tr><tr class="odd"><td></td><td>prev: null,</td></tr><tr class="even"><td></td><td>parent: [Object] } },</td></tr><tr class="odd"><td></td><td>â€˜1â€™:</td></tr><tr class="even"><td></td><td>{ type: â€˜tagâ€™</td></tr><tr class="odd"><td></td><td>â€¦</td></tr></tbody></table>

We check to make sure there are exactly 45 elements returned (the number of U.S. presidents), meaning there arenâ€™t any extra hidden â€œbigâ€ tags elsewhere on the page. Now, we can go through and grab a list of links to all 45 presidential Wikipedia pages by getting them from the â€œattribsâ€ section of each element.

<table><tbody><tr class="odd"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="even"><td></td><td>const $ = require(â€˜cheerioâ€™);</td></tr><tr class="odd"><td></td><td>const url = â€˜https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_Statesâ€™;</td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td>rp(url)</td></tr><tr class="even"><td></td><td>.then(function(html){</td></tr><tr class="odd"><td></td><td>//success!</td></tr><tr class="even"><td></td><td>const wikiUrls = [];</td></tr><tr class="odd"><td></td><td>for (let i = 0; i &lt; 45; i++) {</td></tr><tr class="even"><td></td><td>wikiUrls.push($(â€˜big &gt; aâ€™, html)[i].attribs.href);</td></tr><tr class="odd"><td></td><td>}</td></tr><tr class="even"><td></td><td>console.log(wikiUrls);</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>.catch(function(err){</td></tr><tr class="odd"><td></td><td>//handle error</td></tr><tr class="even"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>[</td></tr><tr class="odd"><td></td><td>â€˜/wiki/George_Washingtonâ€™,</td></tr><tr class="even"><td></td><td>â€˜/wiki/John_Adamsâ€™,</td></tr><tr class="odd"><td></td><td>â€˜/wiki/Thomas_Jeffersonâ€™,</td></tr><tr class="even"><td></td><td>â€˜/wiki/James_Madisonâ€™,</td></tr><tr class="odd"><td></td><td>â€˜/wiki/James_Monroeâ€™,</td></tr><tr class="even"><td></td><td>â€˜/wiki/John_Quincy_Adamsâ€™,</td></tr><tr class="odd"><td></td><td>â€˜/wiki/Andrew_Jacksonâ€™,</td></tr><tr class="even"><td></td><td>â€¦</td></tr><tr class="odd"><td></td><td>]</td></tr></tbody></table>

Now we have a list of all 45 presidential Wikipedia pages. Letâ€™s create a new file (named potusParse.js), which will contain a function to take a presidential Wikipedia page and return the presidentâ€™s name and birthday. First things first, letâ€™s get the raw HTML from George Washingtonâ€™s Wikipedia page.

<table><tbody><tr class="odd"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="even"><td></td><td>const url = â€˜https://en.wikipedia.org/wiki/George_Washingtonâ€™;</td></tr><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>rp(url)</td></tr><tr class="odd"><td></td><td>.then(function(html) {</td></tr><tr class="even"><td></td><td>console.log(html);</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>.catch(function(err) {</td></tr><tr class="odd"><td></td><td>//handle error</td></tr><tr class="even"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td>&lt;html class=â€œclient-nojsâ€ lang=â€œenâ€ dir=â€œltrâ€&gt;</td></tr><tr class="even"><td></td><td>&lt;head&gt;</td></tr><tr class="odd"><td></td><td>&lt;meta charset=â€œUTF-8â€/&gt;</td></tr><tr class="even"><td></td><td>&lt;title&gt;George Washington - Wikipedia&lt;/title&gt;</td></tr><tr class="odd"><td></td><td>â€¦</td></tr></tbody></table>

Letâ€™s once again use Chrome DevTools to find the syntax of the code we want to parse, so that we can extract the name and birthday with Cheerio.js.

![](https://cdn-media-1.freecodecamp.org/images/1*exzZbuIwfrCcbTM2rr9_bw.png)

![](https://cdn-media-1.freecodecamp.org/images/1*yth6AmHpywM77n0wEprpiA.png)

So we see that the name is in a class called â€œfirstHeadingâ€ and the birthday is in a class called â€œbdayâ€. Letâ€™s modify our code to use Cheerio.js to extract these two classes.

<table><tbody><tr class="odd"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="even"><td></td><td>const $ = require(â€˜cheerioâ€™);</td></tr><tr class="odd"><td></td><td>const url = â€˜https://en.wikipedia.org/wiki/George_Washingtonâ€™;</td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td>rp(url)</td></tr><tr class="even"><td></td><td>.then(function(html) {</td></tr><tr class="odd"><td></td><td>console.log(<span class="math inline">$('.firstHeading', html).text());&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td id="file-potusparse-js-v2-L8" data-line-number="8"&gt;&lt;/td&gt;&lt;td id="file-potusparse-js-v2-LC8"&gt;console.log($</span>(â€˜.bdayâ€™, html).text());</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.catch(function(err) {</td></tr><tr class="even"><td></td><td>//handle error</td></tr><tr class="odd"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td>George Washington</td></tr><tr class="even"><td></td><td>1732-02-22</td></tr></tbody></table>

### Putting it all together

Perfect! Now letâ€™s wrap this up into a function and export it from this module.

<table><tbody><tr class="odd"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="even"><td></td><td>const $ = require(â€˜cheerioâ€™);</td></tr><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>const potusParse = function(url) {</td></tr><tr class="odd"><td></td><td>return rp(url)</td></tr><tr class="even"><td></td><td>.then(function(html) {</td></tr><tr class="odd"><td></td><td>return {</td></tr><tr class="even"><td></td><td>name: $(â€˜.firstHeadingâ€™, html).text(),</td></tr><tr class="odd"><td></td><td>birthday: $(â€˜.bdayâ€™, html).text(),</td></tr><tr class="even"><td></td><td>};</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>.catch(function(err) {</td></tr><tr class="odd"><td></td><td>//handle error</td></tr><tr class="even"><td></td><td>});</td></tr><tr class="odd"><td></td><td>};</td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td>module.exports = potusParse;</td></tr></tbody></table>

Now letâ€™s return to our original file potusScraper.js and require the potusParse.js module. Weâ€™ll then apply it to the list of wikiUrls we gathered earlier.

<table><tbody><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="odd"><td></td><td>const $ = require(â€˜cheerioâ€™);</td></tr><tr class="even"><td></td><td>const potusParse = require(â€˜./potusParseâ€™);</td></tr><tr class="odd"><td></td><td>const url = â€˜https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_Statesâ€™;</td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td>rp(url)</td></tr><tr class="even"><td></td><td>.then(function(html) {</td></tr><tr class="odd"><td></td><td>//success!</td></tr><tr class="even"><td></td><td>const wikiUrls = [];</td></tr><tr class="odd"><td></td><td>for (let i = 0; i &lt; 45; i++) {</td></tr><tr class="even"><td></td><td>wikiUrls.push($(â€˜big &gt; aâ€™, html)[i].attribs.href);</td></tr><tr class="odd"><td></td><td>}</td></tr><tr class="even"><td></td><td>return Promise.all(</td></tr><tr class="odd"><td></td><td>wikiUrls.map(function(url) {</td></tr><tr class="even"><td></td><td>return potusParse(â€˜https://en.wikipedia.orgâ€™ + url);</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>);</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>.then(function(presidents) {</td></tr><tr class="odd"><td></td><td>console.log(presidents);</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.catch(function(err) {</td></tr><tr class="even"><td></td><td>//handle error</td></tr><tr class="odd"><td></td><td>console.log(err);</td></tr><tr class="even"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>[</td></tr><tr class="odd"><td></td><td>{ name: â€˜George Washingtonâ€™, birthday: â€˜1732-02-22â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜John Adamsâ€™, birthday: â€˜1735-10-30â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Thomas Jeffersonâ€™, birthday: â€˜1743-04-13â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜James Madisonâ€™, birthday: â€˜1751-03-16â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜James Monroeâ€™, birthday: â€˜1758-04-28â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜John Quincy Adamsâ€™, birthday: â€˜1767-07-11â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Andrew Jacksonâ€™, birthday: â€˜1767-03-15â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Martin Van Burenâ€™, birthday: â€˜1782-12-05â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜William Henry Harrisonâ€™, birthday: â€˜1773-02-09â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜John Tylerâ€™, birthday: â€˜1790-03-29â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜James K. Polkâ€™, birthday: â€˜1795-11-02â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Zachary Taylorâ€™, birthday: â€˜1784-11-24â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Millard Fillmoreâ€™, birthday: â€˜1800-01-07â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Franklin Pierceâ€™, birthday: â€˜1804-11-23â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜James Buchananâ€™, birthday: â€˜1791-04-23â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Abraham Lincolnâ€™, birthday: â€˜1809-02-12â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Andrew Johnsonâ€™, birthday: â€˜1808-12-29â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Ulysses S. Grantâ€™, birthday: â€˜1822-04-27â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Rutherford B. Hayesâ€™, birthday: â€˜1822-10-04â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜James A. Garfieldâ€™, birthday: â€˜1831-11-19â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Chester A. Arthurâ€™, birthday: â€˜1829-10-05â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Grover Clevelandâ€™, birthday: â€˜1837-03-18â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Benjamin Harrisonâ€™, birthday: â€˜1833-08-20â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Grover Clevelandâ€™, birthday: â€˜1837-03-18â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜William McKinleyâ€™, birthday: â€˜1843-01-29â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Theodore Rooseveltâ€™, birthday: â€˜1858-10-27â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜William Howard Taftâ€™, birthday: â€˜1857-09-15â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Woodrow Wilsonâ€™, birthday: â€˜1856-12-28â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Warren G. Hardingâ€™, birthday: â€˜1865-11-02â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Calvin Coolidgeâ€™, birthday: â€˜1872-07-04â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Herbert Hooverâ€™, birthday: â€˜1874-08-10â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Franklin D. Rooseveltâ€™, birthday: â€˜1882-01-30â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Harry S. Trumanâ€™, birthday: â€˜1884-05-08â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Dwight D. Eisenhowerâ€™, birthday: â€˜1890-10-14â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜John F. Kennedyâ€™, birthday: â€˜1917-05-29â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Lyndon B. Johnsonâ€™, birthday: â€˜1908-08-27â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Richard Nixonâ€™, birthday: â€˜1913-01-09â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Gerald Fordâ€™, birthday: â€˜1913-07-14â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Jimmy Carterâ€™, birthday: â€˜1924-10-01â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Ronald Reaganâ€™, birthday: â€˜1911-02-06â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜George H. W. Bushâ€™, birthday: â€˜1924-06-12â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Bill Clintonâ€™, birthday: â€˜1946-08-19â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜George W. Bushâ€™, birthday: â€˜1946-07-06â€™ },</td></tr><tr class="even"><td></td><td>{ name: â€˜Barack Obamaâ€™, birthday: â€˜1961-08-04â€™ },</td></tr><tr class="odd"><td></td><td>{ name: â€˜Donald Trumpâ€™, birthday: â€˜1946-06-14â€™ }</td></tr><tr class="even"><td></td><td>]</td></tr></tbody></table>

### Rendering JavaScript Pages

VoilÃ ! A list of the names and birthdays of all 45 U.S. presidents. Using just the request-promise module and Cheerio.js should allow you to scrape the vast majority of sites on the internet.

Recently, however, many sites have begun using JavaScript to generate dynamic content on their websites. This causes a problem for request-promise and other similar HTTP request libraries (such as axios and fetch), because they only get the response from the initial request, but they cannot execute the JavaScript the way a web browser can.

Thus, to scrape sites that require JavaScript execution, we need another solution. In our next example, we will get the titles for all of the posts on the front page of Reddit. Letâ€™s see what happens when we try to use request-promise as we did in the previous example.

Output:

<table><tbody><tr class="odd"><td></td><td>const rp = require(â€˜request-promiseâ€™);</td></tr><tr class="even"><td></td><td>const url = â€˜https://www.reddit.comâ€™;</td></tr><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>rp(url)</td></tr><tr class="odd"><td></td><td>.then(function(html){</td></tr><tr class="even"><td></td><td>//success!</td></tr><tr class="odd"><td></td><td>console.log(html);</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.catch(function(err){</td></tr><tr class="even"><td></td><td>//handle error</td></tr><tr class="odd"><td></td><td>});</td></tr><tr class="even"><td></td><td>}</td></tr></tbody></table>

Hereâ€™s what the output looks like:

<table><tbody><tr class="odd"><td></td><td>&lt;!DOCTYPE html&gt;&lt;html</td></tr><tr class="even"><td></td><td>lang=â€œenâ€&gt;&lt;head&gt;&lt;title&gt;reddit: the front page of the</td></tr><tr class="odd"><td></td><td>internet&lt;/title&gt;</td></tr><tr class="even"><td></td><td>â€¦</td></tr></tbody></table>

![](https://cdn-media-1.freecodecamp.org/images/1*mKzPVGRR4CFKMwQw5y_YnQ.png)

Hmmmâ€¦not quite what we want. Thatâ€™s because getting the actual content requires you to run the JavaScript on the page! With Puppeteer, thatâ€™s no problem.

Puppeteer is an extremely popular new module brought to you by the Google Chrome team that allows you to control a headless browser. This is perfect for programmatically scraping pages that require JavaScript execution. Letâ€™s get the HTML from the front page of Reddit using Puppeteer instead of request-promise.

<table><tbody><tr class="odd"><td></td><td>const puppeteer = require(â€˜puppeteerâ€™);</td></tr><tr class="even"><td></td><td>const url = â€˜https://www.reddit.comâ€™;</td></tr><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td>puppeteer</td></tr><tr class="odd"><td></td><td>.launch()</td></tr><tr class="even"><td></td><td>.then(function(browser) {</td></tr><tr class="odd"><td></td><td>return browser.newPage();</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.then(function(page) {</td></tr><tr class="even"><td></td><td>return page.goto(url).then(function() {</td></tr><tr class="odd"><td></td><td>return page.content();</td></tr><tr class="even"><td></td><td>});</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>.then(function(html) {</td></tr><tr class="odd"><td></td><td>console.log(html);</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.catch(function(err) {</td></tr><tr class="even"><td></td><td>//handle error</td></tr><tr class="odd"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td>&lt;!DOCTYPE html&gt;&lt;html lang=â€œenâ€&gt;&lt;head&gt;&lt;link</td></tr><tr class="even"><td></td><td>href=â€œ//c.amazon-adsystem.com/aax2/apstag.jsâ€ rel=â€œpreloadâ€</td></tr><tr class="odd"><td></td><td>as=â€œscriptâ€&gt;</td></tr><tr class="even"><td></td><td>â€¦</td></tr></tbody></table>

Nice! The page is filled with the correct content!

![](https://cdn-media-1.freecodecamp.org/images/1*N5HtAiijcMEB_fBQvPd7Ow.png)

Now we can use Chrome DevTools like we did in the previous example.

![](https://cdn-media-1.freecodecamp.org/images/1*tHSgjPMvn3M26N2f7Q2B1Q.png)

It looks like Reddit is putting the titles inside â€œh2â€ tags. Letâ€™s use Cheerio.js to extract the h2 tags from the page.

<table><tbody><tr class="odd"><td></td><td>const puppeteer = require(â€˜puppeteerâ€™);</td></tr><tr class="even"><td></td><td>const $ = require(â€˜cheerioâ€™);</td></tr><tr class="odd"><td></td><td>const url = â€˜https://www.reddit.comâ€™;</td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td>puppeteer</td></tr><tr class="even"><td></td><td>.launch()</td></tr><tr class="odd"><td></td><td>.then(function(browser) {</td></tr><tr class="even"><td></td><td>return browser.newPage();</td></tr><tr class="odd"><td></td><td>})</td></tr><tr class="even"><td></td><td>.then(function(page) {</td></tr><tr class="odd"><td></td><td>return page.goto(url).then(function() {</td></tr><tr class="even"><td></td><td>return page.content();</td></tr><tr class="odd"><td></td><td>});</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.then(function(html) {</td></tr><tr class="even"><td></td><td><span class="math inline">$('h2', html).each(function() {&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td id="file-reddit-js-v3-L17" data-line-number="17"&gt;&lt;/td&gt;&lt;td id="file-reddit-js-v3-LC17"&gt;console.log($</span>(this).text());</td></tr><tr class="odd"><td></td><td>});</td></tr><tr class="even"><td></td><td>})</td></tr><tr class="odd"><td></td><td>.catch(function(err) {</td></tr><tr class="even"><td></td><td>//handle error</td></tr><tr class="odd"><td></td><td>});</td></tr></tbody></table>

Output:

<table><tbody><tr class="odd"><td></td><td>Russian Pipeline. Upvote so that this is the first image people see when they Google â€œRussian Pipelineâ€</td></tr><tr class="even"><td></td><td>John F. Kennedy Jr.Â Sitting in the pilot seat of the Marine One circa 1963</td></tr><tr class="odd"><td></td><td>I didnâ€™t take it as a compliment.</td></tr><tr class="even"><td></td><td>How beautiful is this</td></tr><tr class="odd"><td></td><td>Hustle like Faye</td></tr><tr class="even"><td></td><td>The power of a salt water crocodileâ€™s tail.</td></tr><tr class="odd"><td></td><td>Iâ€™m 36, and will be dead inside of a year.</td></tr><tr class="even"><td></td><td>F***ing genius.</td></tr><tr class="odd"><td></td><td>TIL Anthony Daniels, who endured years of discomfort in the C-3PO costume, was so annoyed by Alan Tudyk (Rogue One) playing K-2SO in the comfort of a motion-capture suit that he cursed at Tudyk. Tudyk later joked that a â€œfuck youâ€ from Daniels was among the highest compliments he had ever received.</td></tr><tr class="even"><td></td><td>Reminder about the fact UC Davis paid over $100k to remove this photo from the internet.</td></tr><tr class="odd"><td></td><td>King of the Hill reruns will start airing on Comedy Central July 24th</td></tr><tr class="even"><td></td><td>[Image] Slow and steady</td></tr><tr class="odd"><td></td><td>White House: Trump open to Russia questioning US citizens</td></tr><tr class="even"><td></td><td>Godzilla: King of the Monsters Teaser Banner</td></tr><tr class="odd"><td></td><td>He tried</td></tr><tr class="even"><td></td><td>Soldier reunited with his dog after being away.</td></tr><tr class="odd"><td></td><td>Hiring a hitman on yourself and preparing for battle is the ultimate extreme sport.</td></tr><tr class="even"><td></td><td>Two paintballs colliding midair</td></tr><tr class="odd"><td></td><td>My thoughts &amp; prayers are with those ears</td></tr><tr class="even"><td></td><td>When even your fantasy starts dropping hints</td></tr><tr class="odd"><td></td><td>Elon Muskâ€™s apology is out</td></tr><tr class="even"><td></td><td>â€œWhen youâ€™re going private so you plant trees to throw some last shade at TDNW before you vanish.â€ Thanosâ€™ farm advances. The soul children will have full bellies. 1024 points will give him the resources to double, and irrigate, his farm. (See comment)</td></tr><tr class="odd"><td></td><td>Some leaders prefer chess, others prefer hungry hippos. Travis Chapman, oil, 2018</td></tr><tr class="even"><td></td><td>The S.S. Ste. Claire, retired from ferrying amusement park goers, now ferries The Damned across the river Styx.</td></tr><tr class="odd"><td></td><td>A soldier is reunited with his dog</td></tr><tr class="even"><td></td><td><em>hits blunt</em></td></tr><tr class="odd"><td></td><td>Today I Learned</td></tr><tr class="even"><td></td><td>Black Panther Scene Representing the Pan-African Flag</td></tr><tr class="odd"><td></td><td>The precision of this hydraulic press.</td></tr><tr class="even"><td></td><td>Let bring the game to another level</td></tr><tr class="odd"><td></td><td>When youâ€™re fighting a Dark Souls boss and you gamble to get â€˜just one extra hitâ€™ in instead of rolling out of range.</td></tr><tr class="even"><td></td><td>â€œI check for trapsâ€</td></tr><tr class="odd"><td></td><td>Anon finds his home at last</td></tr><tr class="even"><td></td><td>Heâ€™s hungry</td></tr><tr class="odd"><td></td><td>Being a single mother is a thankless job.</td></tr><tr class="even"><td></td><td>TIL That when youâ€™re pulling out Minigun, youâ€™re actually pulling out suitcase that then transforms into Minigun.</td></tr><tr class="odd"><td></td><td>OMG guys donâ€™t look!!! ğŸ™ˆğŸ™ˆğŸ™ˆ</td></tr><tr class="even"><td></td><td>hyubsamaâ€™s emote of his own face denied for political reasons because twitch thinks its a picture of Kim Jong Un</td></tr></tbody></table>

### Additional Resources

And thereâ€™s the list! At this point you should feel comfortable writing your first web scraper to gather data from any website. Here are a few additional resources that you may find helpful during your web scraping journey:

-   [List of web scraping proxy services](https://www.scraperapi.com/blog/the-10-best-rotating-proxy-services-for-web-scraping)
-   [List of handy web scraping tools](https://www.scraperapi.com/blog/the-10-best-web-scraping-tools)
-   [List of web scraping tips](https://www.scraperapi.com/blog/5-tips-for-web-scraping)
-   [Comparison of web scraping proxies](https://www.scraperapi.com/blog/free-shared-dedicated-datacenter-residential-rotating-proxies-for-web-scraping)
-   [Cheerio Documentation](https://github.com/cheeriojs/cheerio)
-   [Puppeteer Documentation](https://github.com/GoogleChrome/puppeteer)

------------------------------------------------------------------------
